#+begin_src sh :results verbatim :capture both
./cmakebuild/dcgmi/dcgmi -v
#+end_src

#+RESULTS:
#+begin_example
Version : 3.2.6
Build Date : 2023-11-05
Commit ID : 282bb8f82139727248aabaf4cd069678d82eb0fa
Branch Name : master
CPU Arch : x86_64
Build Platform : Linux 6.2.0-35-generic #35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Oct  6 10:23:26 UTC 2 x86_64
CRC : 3438f2916bb85ae99e0fd7baffc77fdd

Hostengine build info:
Version : 3.2.6
Build Date : 2023-11-05
Commit ID : 282bb8f82139727248aabaf4cd069678d82eb0fa
Branch Name : master
CPU Arch : x86_64
Build Platform : Linux 6.2.0-35-generic #35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Oct  6 10:23:26 UTC 2 x86_64
CRC : 3438f2916bb85ae99e0fd7baffc77fdd
#+end_example


#+begin_src sh :results verbatim :capture both
./cmakebuild/dcgmi/dcgmi topo
#+end_src

#+RESULTS:
: Getting topology is not supported for group 2147483647

Now we make install and export the local lib and run the backend

#+begin_src sh :results verbatim :capture both
  sudo su -
  make install 
  export LD_LIBRARY_PATH=/usr/local/lib/:$LD_LIBRARY_PATH
  nv-hostengine 
#+end_src

Now we can see no results in a new way

#+begin_src sh :results verbatim :capture both
dcgmi topo
#+end_src

#+RESULTS:
: Getting topology is not supported for group 2147483647


#+begin_src sh :results verbatim :capture both
  dcgmi diag -r DEBUG -j
#+end_src

#+RESULTS:
: {
: 	"DCGM GPU Diagnostic" : 
: 	{
: 		"runtime_error" : "Error when executing the diagnostic: The NVVS binary was not found in the specified location; please install it to /usr/share/nvidia-validation-suite/ or set environment variable NVVS_BIN_PATH to the directory containing nvvs. If you set NVVS_BIN_PATH, please restart the DCGM service (nv-hostengine) if it is active.\nNvvs stderr: \n\n",
: 		"version" : "3.2.6"
: 	}
: }
: 
  
#+begin_src sh :results verbatim :capture both
  dcgmi diag -r {level} -j
  dcgmi discovery -l
  dcgmi fieldgroup -l
  dcgmi group -l
  dcgmi modules -l
  dcgmi health -c -j
  CUDA generator scenario:
  /usr/bin/dcgmproftester11 --no-dcgm-validation -t {FieldID} -d 10
  dcgmi dmon -e {ListOfFieldIDs} -c 15

#+end_src


#+begin_src sh :results verbatim :capture both
dcgmi diag -r DEBUG -j
#+end_src

#+RESULTS:
: {
: 	"DCGM GPU Diagnostic" : 
: 	{
: 		"runtime_error" : "Plugins directory was not found.  Please check paths or use -p to set it.",
: 		"version" : "3.2.6"
: 	}
: }
: 


#+begin_src sh :results verbatim :capture both
 nsys status -e
#+end_src

#+RESULTS:
#+begin_example
Timestamp counter supported: Yes

CPU Profiling Environment Check
Root privilege: disabled
Linux Kernel Paranoid Level = 4
Linux Distribution = Ubuntu
Linux Kernel Version = 6.2.0-35-generic: OK
Linux perf_event_open syscall available: Fail
Sampling trigger event available: Fail
Intel(c) Last Branch Record support: Not Available
CPU Profiling Environment (process-tree): Fail
CPU Profiling Environment (system-wide): Fail

See the product documentation at https://docs.nvidia.com/nsight-systems for more information,
including information on how to set the Linux Kernel Paranoid Level.
#+end_example


#+begin_src sh :results verbatim :capture both
 sudo nsys status -e
#+end_src

#+RESULTS:
#+begin_example
Timestamp counter supported: Yes

CPU Profiling Environment Check
Root privilege: enabled
Linux Kernel Paranoid Level = 4
Linux Distribution = Ubuntu
Linux Kernel Version = 6.2.0-35-generic: OK
Linux perf_event_open syscall available: OK
Sampling trigger event available: OK
Intel(c) Last Branch Record support: Available
CPU Profiling Environment (process-tree): OK
CPU Profiling Environment (system-wide): OK

See the product documentation at https://docs.nvidia.com/nsight-systems for more information,
including information on how to set the Linux Kernel Paranoid Level.
#+end_example


To use NVIDIA Nsight Systems (nsys) to check the installation, list GPUs, and trace hotspots in your local CUDA processes on a GPU, you can follow these high-level commands:

1. **Check Installation**:
   - To check if Nsight Systems is installed, open a terminal and run:

#+begin_src sh :results verbatim :capture both
  nsys --version
#+end_src

#+RESULTS:
: NVIDIA Nsight Systems version 2023.3.3.42-233333266658v0


2. **List GPUs**:
   - To list the available GPUs on your system, run:

#+begin_src sh :results verbatim :capture both

sudo   nsys profile --gpu-metrics-device=help
#+end_src

#+RESULTS:
: Possible --gpu-metrics-device values are:
: 	0: NVIDIA GeForce RTX 3080 Ti PCI[0000:01:00.0]
: 	all: Select all supported GPUs
: 	none: Disable GPU Metrics [Default]


    
3. **Trace Hotspots**:
   - To trace hotspots in your local CUDA processes on a specific GPU, you can use the following command:

#+begin_src sh :results verbatim :capture both
  sudo nsys profile --stats=true --force-overwrite true --trace=cuda,nvtx -o my_trace_report.qdrep 
#+end_src

     #+RESULTS:


     Replace `./your_cuda_program` with the path to your CUDA application.

